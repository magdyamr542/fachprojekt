{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b26ea4d1d33ade197c4df046c3f995f",
     "grade": false,
     "grade_id": "cell-84add916f922e23f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Fachprojekt Dokumentenanalyse** *WS 22/23* -- *Philipp Oberdiek, Gernot A. Fink* -- *Technische Universität Dortmund, Lehrstuhl XII, Mustererkennung in eingebetteten Systemen*\n",
    "---\n",
    "# Aufgabe 1: Brown Corpus\n",
    "\n",
    "In der ersten Aufgabe sollen Sie sich mit dem Brown Corpus vertraut machen.\n",
    " - Laden Sie den Corpus und schauen Sie sich dessen Aufbau an.\n",
    " - Analysieren Sie den Corpus in dem Sie Wortstatistiken bestimmen.\n",
    " - Verbessern Sie die Aussagekraft der Statistiken.\n",
    "\n",
    "## Laden des Corpus\n",
    "Für das Fachprojekt benötigen Sie die NLTK (http://www.nltk.org/) Datensätze \"brown\" und \"stopwords\". Falls diese noch nicht lokal auf Ihrem Rechner verfügbar sein sollten, können Sie sie über den \"NLTK Downloader\" herunterladen. Ein entsprechender Dialog öffnet sich in diesem Fall automatisch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de525fc23f4b5e8224107f6d35b71943",
     "grade": false,
     "grade_id": "cell-c45e5706e93c60a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "    \n",
    "from common.corpus import CorpusLoader\n",
    "\n",
    "CorpusLoader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e72ca53544e59757605373ea31a3cf8",
     "grade": false,
     "grade_id": "cell-85c0a3032dd46c36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Im Folgenden werden einige grundlegende Statistiken des Brown Corpus ausgegeben, die vor allem etwas über dessen Struktur / Aufbau aussagen.\n",
    "\n",
    "Siehe auch: http://en.wikipedia.org/wiki/Brown_Corpus\n",
    "\n",
    "Der Corpus enthält verschiedene Kategorien, in die Dokumente einsortiert sind. Ein Dokument besteht aus Wörtern. Als nächstes sehen Sie, wie Sie auf Kategorien, Dokumente und Wörter zugreifen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d982f9083f9e1bc463d942df80050a3e",
     "grade": false,
     "grade_id": "cell-69a976882afa9bc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "brown = CorpusLoader.brown_corpus()\n",
    "brown_categories = brown.categories()\n",
    "brown_documents = brown.fileids()\n",
    "brown_words = brown.words()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71865bb10cf59f6a7ca5c80f9cd1f5f1",
     "grade": false,
     "grade_id": "cell-e7dbe7aac64a0953",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Geben Sie nun die Gesamtanzahl von Kategorien, Dokumenten und Wörtern mit print aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl Kategorien: 15\n",
      "Gesamtanzahl Dokumenten: 500\n",
      "Gesamtanzahl Woertern: 1161192\n"
     ]
    }
   ],
   "source": [
    "print(\"Gesamtanzahl Kategorien:\", len(brown_categories))\n",
    "print(\"Gesamtanzahl Dokumenten:\", len(brown_documents))\n",
    "print(\"Gesamtanzahl Woertern:\", len(brown_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f8d008e6a7ff45d9bc0f13b3152c0e9",
     "grade": false,
     "grade_id": "cell-77636fba7f7320f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Geben Sie die Namen der einzelnen Kategorien aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories (15):\n",
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "docs (500):\n",
      "['ca01', 'ca02', 'ca03', 'ca04', 'ca05', 'ca06', 'ca07', 'ca08', 'ca09', 'ca10', 'ca11', 'ca12', 'ca13', 'ca14', 'ca15', 'ca16', 'ca17', 'ca18', 'ca19', 'ca20', 'ca21', 'ca22', 'ca23', 'ca24', 'ca25', 'ca26', 'ca27', 'ca28', 'ca29', 'ca30', 'ca31', 'ca32', 'ca33', 'ca34', 'ca35', 'ca36', 'ca37', 'ca38', 'ca39', 'ca40', 'ca41', 'ca42', 'ca43', 'ca44', 'cb01', 'cb02', 'cb03', 'cb04', 'cb05', 'cb06', 'cb07', 'cb08', 'cb09', 'cb10', 'cb11', 'cb12', 'cb13', 'cb14', 'cb15', 'cb16', 'cb17', 'cb18', 'cb19', 'cb20', 'cb21', 'cb22', 'cb23', 'cb24', 'cb25', 'cb26', 'cb27', 'cc01', 'cc02', 'cc03', 'cc04', 'cc05', 'cc06', 'cc07', 'cc08', 'cc09', 'cc10', 'cc11', 'cc12', 'cc13', 'cc14', 'cc15', 'cc16', 'cc17', 'cd01', 'cd02', 'cd03', 'cd04', 'cd05', 'cd06', 'cd07', 'cd08', 'cd09', 'cd10', 'cd11', 'cd12', 'cd13', 'cd14', 'cd15', 'cd16', 'cd17', 'ce01', 'ce02', 'ce03', 'ce04', 'ce05', 'ce06', 'ce07', 'ce08', 'ce09', 'ce10', 'ce11', 'ce12', 'ce13', 'ce14', 'ce15', 'ce16', 'ce17', 'ce18', 'ce19', 'ce20', 'ce21', 'ce22', 'ce23', 'ce24', 'ce25', 'ce26', 'ce27', 'ce28', 'ce29', 'ce30', 'ce31', 'ce32', 'ce33', 'ce34', 'ce35', 'ce36', 'cf01', 'cf02', 'cf03', 'cf04', 'cf05', 'cf06', 'cf07', 'cf08', 'cf09', 'cf10', 'cf11', 'cf12', 'cf13', 'cf14', 'cf15', 'cf16', 'cf17', 'cf18', 'cf19', 'cf20', 'cf21', 'cf22', 'cf23', 'cf24', 'cf25', 'cf26', 'cf27', 'cf28', 'cf29', 'cf30', 'cf31', 'cf32', 'cf33', 'cf34', 'cf35', 'cf36', 'cf37', 'cf38', 'cf39', 'cf40', 'cf41', 'cf42', 'cf43', 'cf44', 'cf45', 'cf46', 'cf47', 'cf48', 'cg01', 'cg02', 'cg03', 'cg04', 'cg05', 'cg06', 'cg07', 'cg08', 'cg09', 'cg10', 'cg11', 'cg12', 'cg13', 'cg14', 'cg15', 'cg16', 'cg17', 'cg18', 'cg19', 'cg20', 'cg21', 'cg22', 'cg23', 'cg24', 'cg25', 'cg26', 'cg27', 'cg28', 'cg29', 'cg30', 'cg31', 'cg32', 'cg33', 'cg34', 'cg35', 'cg36', 'cg37', 'cg38', 'cg39', 'cg40', 'cg41', 'cg42', 'cg43', 'cg44', 'cg45', 'cg46', 'cg47', 'cg48', 'cg49', 'cg50', 'cg51', 'cg52', 'cg53', 'cg54', 'cg55', 'cg56', 'cg57', 'cg58', 'cg59', 'cg60', 'cg61', 'cg62', 'cg63', 'cg64', 'cg65', 'cg66', 'cg67', 'cg68', 'cg69', 'cg70', 'cg71', 'cg72', 'cg73', 'cg74', 'cg75', 'ch01', 'ch02', 'ch03', 'ch04', 'ch05', 'ch06', 'ch07', 'ch08', 'ch09', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch16', 'ch17', 'ch18', 'ch19', 'ch20', 'ch21', 'ch22', 'ch23', 'ch24', 'ch25', 'ch26', 'ch27', 'ch28', 'ch29', 'ch30', 'cj01', 'cj02', 'cj03', 'cj04', 'cj05', 'cj06', 'cj07', 'cj08', 'cj09', 'cj10', 'cj11', 'cj12', 'cj13', 'cj14', 'cj15', 'cj16', 'cj17', 'cj18', 'cj19', 'cj20', 'cj21', 'cj22', 'cj23', 'cj24', 'cj25', 'cj26', 'cj27', 'cj28', 'cj29', 'cj30', 'cj31', 'cj32', 'cj33', 'cj34', 'cj35', 'cj36', 'cj37', 'cj38', 'cj39', 'cj40', 'cj41', 'cj42', 'cj43', 'cj44', 'cj45', 'cj46', 'cj47', 'cj48', 'cj49', 'cj50', 'cj51', 'cj52', 'cj53', 'cj54', 'cj55', 'cj56', 'cj57', 'cj58', 'cj59', 'cj60', 'cj61', 'cj62', 'cj63', 'cj64', 'cj65', 'cj66', 'cj67', 'cj68', 'cj69', 'cj70', 'cj71', 'cj72', 'cj73', 'cj74', 'cj75', 'cj76', 'cj77', 'cj78', 'cj79', 'cj80', 'ck01', 'ck02', 'ck03', 'ck04', 'ck05', 'ck06', 'ck07', 'ck08', 'ck09', 'ck10', 'ck11', 'ck12', 'ck13', 'ck14', 'ck15', 'ck16', 'ck17', 'ck18', 'ck19', 'ck20', 'ck21', 'ck22', 'ck23', 'ck24', 'ck25', 'ck26', 'ck27', 'ck28', 'ck29', 'cl01', 'cl02', 'cl03', 'cl04', 'cl05', 'cl06', 'cl07', 'cl08', 'cl09', 'cl10', 'cl11', 'cl12', 'cl13', 'cl14', 'cl15', 'cl16', 'cl17', 'cl18', 'cl19', 'cl20', 'cl21', 'cl22', 'cl23', 'cl24', 'cm01', 'cm02', 'cm03', 'cm04', 'cm05', 'cm06', 'cn01', 'cn02', 'cn03', 'cn04', 'cn05', 'cn06', 'cn07', 'cn08', 'cn09', 'cn10', 'cn11', 'cn12', 'cn13', 'cn14', 'cn15', 'cn16', 'cn17', 'cn18', 'cn19', 'cn20', 'cn21', 'cn22', 'cn23', 'cn24', 'cn25', 'cn26', 'cn27', 'cn28', 'cn29', 'cp01', 'cp02', 'cp03', 'cp04', 'cp05', 'cp06', 'cp07', 'cp08', 'cp09', 'cp10', 'cp11', 'cp12', 'cp13', 'cp14', 'cp15', 'cp16', 'cp17', 'cp18', 'cp19', 'cp20', 'cp21', 'cp22', 'cp23', 'cp24', 'cp25', 'cp26', 'cp27', 'cp28', 'cp29', 'cr01', 'cr02', 'cr03', 'cr04', 'cr05', 'cr06', 'cr07', 'cr08', 'cr09']\n",
      "words (1161192):\n",
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n"
     ]
    }
   ],
   "source": [
    "def print_ds():\n",
    "\tprint(f\"categories ({len(brown_categories)}):\")\n",
    "\tprint(brown_categories)\n",
    "\tprint(f\"docs ({len(brown_documents)}):\")\n",
    "\tprint(brown_documents)\n",
    "\tprint(f\"words ({len(brown_words)}):\")\n",
    "\tprint(brown_words)\n",
    "print_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b496e61c349b9597b5822d7a9cf1192e",
     "grade": false,
     "grade_id": "cell-aec1ec9b2b157652",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Bisher haben Sie noch keine Information über die Struktur des Brown Corpus gewonnen, da sie jeweils die Gesamtzahl von Kategorien, Dokumenten und Wörtern ausgegeben haben.\n",
    "\n",
    "Geben Sie als nächstes die Anzahl von Dokumenten und Wörtern je Kategorie aus.\n",
    "http://www.nltk.org/howto/corpus.html#categorized-corpora\n",
    "\n",
    "**Hilfreiche Funktionen:** `fileids`, `words`\n",
    "\n",
    "Visualisieren Sie die Verteilungen mit Hilfe von horizontalen bar plots. Nutzen Sie dafür die Funktion `hbar_plot` aus dem Modul `common.visualization`.\n",
    "http://matplotlib.org/examples/lines_bars_and_markers/barh_demo.html\n",
    "\n",
    "Optional: Plotten Sie die Verteilungen mit vertikalen bar plots.\n",
    "Vermeiden Sie, dass sich die an der x-Achse aufgetragenen labels überlappen\n",
    "http://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.set_xticklabels\n",
    "Stellen Sie nun die Verteilungen über Dokumente und Wörter in einem gemeinsamen Plot dar. Verwenden Sie unterschiedliche Farben.\n",
    "http://matplotlib.org/examples/api/barchart_demo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_label = []\n",
    "cat_num_words = []\n",
    "cat_num_docs = []\n",
    "for category in brown_categories:\n",
    "\tcat_label.append(category)\n",
    "\tcat_num_words.append(len(brown.words(categories=category)))\n",
    "\tcat_num_docs.append(len(brown.fileids(categories=category)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvisualization\u001b[39;00m \u001b[39mimport\u001b[39;00m hbar_plot\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnum words to categories\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m hbar_plot(cat_num_words , cat_label)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common'"
     ]
    }
   ],
   "source": [
    "from common.visualization import hbar_plot\n",
    "print(\"num words to categories\")\n",
    "hbar_plot(cat_num_words , cat_label)\n",
    "print(\"num docs to categories\")\n",
    "hbar_plot(cat_num_docs , cat_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b60f2113159cabebb74e6bdb63eda4f5",
     "grade": false,
     "grade_id": "cell-65b634808f9087cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die nun zu implementierenden Funktionen spielen eine zentrale Rolle im weiteren Verlauf des Fachprojekts. Achten Sie auf eine effiziente und 'saubere' Umsetzung. Verwenden Sie geeignete Datenstrukturen und passende Python Funktionen. Wenn Ihnen Ihr Ansatz sehr aufwändig vorkommt, haben Sie vermutlich nicht die passenden Datenstrukturen / Algorithmen / (highlevel) Python / NumPy Funktionen verwendet. Fragen Sie in diesem Fall!\n",
    "\n",
    "Schauen Sie sich jetzt schon gründlich die Klassen und deren Interfaces in den mitgelieferten Modulen an. Wenn Sie Ihre Datenstrukturen von Anfang an dazu passend wählen, erleichtert dies deren spätere Benutzung. Zusätzlich bieten diese Klassen bereits etwas Inspiration für Python-typisches Design, wie zum Beispiel Duck-Typing.\n",
    "\n",
    "Zu einigen der vorgebenen Interfaces finden Sie Unit Tests in dem Paket 'utest'. Diese sind sehr hilfreich um zu überprüfen, ob ihre Implementierung zusammen mit anderen mitgelieferten Implementierungen / Interfaces funktionieren wird. Stellen Sie immer sicher, dass die Unit tests für die von Ihnen verwendeten Funktionen erfolgreich sind.  \n",
    "**Hinweis:** Im Verlauf des Fachprojekts werden die Unit Tests nach und nach erfolgreich sein. Falls es sie zu Beginn stört, wenn einzelne Unit Tests fehlschlagen können Sie diese durch einen 'decorator' vor der Methodendefinition vorübergehend abschalten: `@unittest.skip('')`\n",
    "https://docs.python.org/3/library/unittest.html#skipping-tests-and-expected-failures\n",
    "Denken Sie aber daran sie später wieder zu aktivieren.\n",
    "\n",
    "Wenn etwas unklar ist, fragen Sie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "732bdac7aa30bb50b65e1225c6f797f7",
     "grade": false,
     "grade_id": "cell-33394ff308e5cc17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Um Texte / Dokumente semantisch zu analysieren, betrachtet man Verteilungen über Wortvorkommen. Ziel dieser semantischen Analyse soll es letztlich sein unbekannte Dokumente automatisch einer bekannten Kategorie / Klasse zuzuordnen.\n",
    "\n",
    "Bestimmen Sie die 20 häufigsten Wörter des Brown Corpus (insgesamt), sowie die 20 häufigsten Wörter je Kategorie.\n",
    "\n",
    "http://docs.python.org/3/library/collections.html#collections.defaultdict\n",
    "http://docs.python.org/3/library/functions.html#sorted\n",
    "\n",
    "**Hinweis:** Die Dokumentation zu `defaultdict` enthält ein sehr hilfreiches Beispiel.\n",
    "\n",
    "Implementieren Sie die (statische) Funktion `BagOfWords.most_freq_words` im Modul `common.features`. Nutzen Sie die Funktion anschließend um die 20 häufigstens Wörter des Corpus und pro Kategorie auszugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 20 words for the full corpus\n",
      "the | , | . | of | and | to | a | in | that | is | was | for | `` | '' | The | with | it | as | he | his\n",
      "Category=adventure . | , | the | and | a | of | to | `` | '' | was\n",
      "Category=belles_lettres the | , | . | of | and | to | a | in | that | is\n",
      "Category=editorial the | , | . | of | to | and | a | in | is | that\n",
      "Category=fiction , | . | the | and | to | of | a | was | in | he\n",
      "Category=government the | , | of | . | and | to | in | a | for | is\n",
      "Category=hobbies the | , | . | of | and | to | a | in | is | for\n",
      "Category=humor , | the | . | of | and | a | to | `` | '' | in\n",
      "Category=learned the | , | of | . | and | to | in | a | is | that\n",
      "Category=lore the | , | . | of | and | to | a | in | is | that\n",
      "Category=mystery . | , | the | to | and | a | of | was | `` | ''\n",
      "Category=news the | , | . | of | and | to | a | in | for | The\n",
      "Category=religion the | , | of | . | and | to | in | a | is | that\n",
      "Category=reviews , | the | . | of | and | a | to | in | is | ``\n",
      "Category=romance , | . | the | and | to | a | of | `` | '' | was\n",
      "Category=science_fiction , | . | the | of | to | and | '' | `` | a | was\n"
     ]
    }
   ],
   "source": [
    "from common.features import BagOfWords\n",
    "\n",
    "print('\\nTOP 20 words for the full corpus')\n",
    "top_words = BagOfWords.most_freq_words(word_list=brown_words, n_words=20)\n",
    "print(' | '.join(top_words))\n",
    "# TOP 10 words per category\n",
    "for category in brown_categories:\n",
    "\tcategory_words =  brown.words(categories=category)\n",
    "\ttop_words_per_cat = BagOfWords.most_freq_words(word_list=category_words, n_words=10)\n",
    "\tprint( f\"Category={category}\" , ' | '.join(top_words_per_cat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcd12dcd05c5e95e95dbcf9bc902243b",
     "grade": false,
     "grade_id": "cell-f484ad5e63ab8980",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Testen Sie ihre Implementierung mit folgendem Unittest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c25f6be8af0cf6848903444e14238ffa",
     "grade": true,
     "grade_id": "cell-1e30aa3f9e42d85e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "from utest.test_features import BagOfWordsTest\n",
    "\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(BagOfWordsTest(\"test_most_freq_words\"))\n",
    "runner = unittest.TextTestRunner()\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d76049f792bfd4cf907eee2060462579",
     "grade": false,
     "grade_id": "cell-34726a8daf5f59fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Diese Wörter sind nicht besonders charakteristisch für die Unterscheidung verschiedener Kategorien. Daher entfernt man solche wenig aussagekräftigen Wörter vor einer semantischen Analyse. Man bezeichnet diese Wörter als *stopwords*.\n",
    "\n",
    "Eine Liste mit stopwords wird durch NLTK bereitgestellt (siehe oben, sowie im `common.corpus` Modul). Filtern Sie nun alle stopwords bevor Sie die 20 häufigsten Wörter im Brown Corpus (insgesamt und je Kategorie) erneut bestimmen. Achten Sie dabei auf Gross- und Kleinschreibung und filtern Sie auch Satzzeichen (`string.punctuation`).\n",
    "\n",
    "http://www.nltk.org/howto/corpus.html#word-lists-and-lexicons\n",
    "http://docs.python.org/3/library/string.html\n",
    "\n",
    "Geben Sie zunächst stopwords und Satzzeichen auf der Kommandozeile aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from typing import List\n",
    "stop_words = CorpusLoader.stopwords_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7a61f297064d9a098e0004023bc0162",
     "grade": false,
     "grade_id": "cell-2a0d35af554d535a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Mit der Liste von stopwords können Sie noch keine grammatikalischen Varianten von Wörtern erfassen, die ebenfalls nicht entscheidend für die semantische Analyse von Texten sind (zum Beispiel: walking, walked).\n",
    "\n",
    "Verwenden Sie daher den `PorterStemmer` um Wörter auf ihre Wortstämme abzubilden.\n",
    "Geben Sie die 20 häufigsten Wörter nach jedem Filter Schritt aus:\n",
    "\n",
    "1. stopwords und Satzzeichen\n",
    "2. Abbildung auf Wortstämme (stemming)\n",
    "\n",
    "Erläutern Sie Ihre Beobachtungen.\n",
    "\n",
    "Implementieren Sie die Methode `WordListNormalizer.normalize_words` im `common.features` Modul.\n",
    "\n",
    "**Hilfreiche Funktionen:** http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from common.features import WordListNormalizer\n",
    "normalizer =  WordListNormalizer(stop_words)\n",
    "words , stemmed_words  = normalizer.normalize_words(brown_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f9cd87823c5576827c5265ddf4a8d13",
     "grade": false,
     "grade_id": "cell-46e3b26019e65309",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Testen Sie ihre Implementierung mit folgendem Unittest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ae7219857303946e2bd2b99f2edcf1d",
     "grade": true,
     "grade_id": "cell-418d80d8406aa346",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "from utest.test_features import WordListNormalizerTest\n",
    "\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(WordListNormalizerTest(\"test_normalize_words\"))\n",
    "runner = unittest.TextTestRunner()\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "532930a045c70b6179a9e76aad6b950d5161a1fd1537a8fdd1aa5c1fdfc9fb89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
